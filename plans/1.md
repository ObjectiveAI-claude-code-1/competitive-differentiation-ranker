# Implementation Plan: Competitive Differentiation Ranker

## Overview

The Competitive Differentiation Ranker is a **vector function** that evaluates a set of startup ideas simultaneously and produces a probability distribution representing their relative competitive differentiation. Unlike scalar functions that evaluate items in isolation, this function embraces comparative analysis—the output scores sum to approximately 1.

---

## Input Schema Structure

```json
{
  "type": "object",
  "description": "Input for the competitive differentiation ranker. Accepts an array of startup ideas to compare.",
  "properties": {
    "ideas": {
      "type": "array",
      "description": "An array of startup ideas to evaluate for relative competitive differentiation.",
      "items": {
        "anyOf": [
          {
            "type": "string",
            "description": "A text description of a startup idea (elevator pitch, description, etc.)"
          },
          {
            "type": "image",
            "description": "An image-based pitch (pitch deck slide, infographic, etc.)"
          },
          {
            "type": "video",
            "description": "A video pitch (demo video, pitch presentation, etc.)"
          },
          {
            "type": "array",
            "description": "A composite pitch combining multiple media types",
            "items": {
              "anyOf": [
                { "type": "string" },
                { "type": "image" },
                { "type": "video" }
              ]
            }
          }
        ]
      },
      "minItems": 2
    }
  },
  "required": ["ideas"]
}
```

### Field Descriptions

- **ideas**: The array of startup ideas to compare. Must contain at least 2 ideas. Each idea can be:
  - A text string describing the startup concept
  - An image (pitch deck slide, infographic)
  - A video (demo, pitch presentation)
  - A composite array combining multiple media types

---

## Input Maps

No input maps are needed. This function evaluates all ideas together in each task, not individually. The comparative nature requires the full set to be visible in each evaluation.

The system prompt and user message for each task will present ALL ideas together, asking the model to comparatively rank them on each dimension.

---

## Function Definition Structure

```json
{
  "type": "vector.function",
  "description": "Rank startup ideas by relative competitive differentiation. Evaluates a set of ideas simultaneously, assessing uniqueness, defensibility, competitive positioning, and pivot barriers. Returns a probability distribution where higher scores indicate more differentiated and defensible positions. Scores sum to approximately 1.",
  "input_schema": { ... },
  "tasks": [
    // Task 1: Conceptual Territory Uniqueness
    // Task 2: Network Effect Potential
    // Task 3: Data Moat Strength
    // Task 4: Switching Cost Potential
    // Task 5: Scale Economy Advantages
    // Task 6: Dominance Relationships
    // Task 7: Category Position (Blue/Red Ocean)
    // Task 8: Positional Clarity
    // Task 9: Technical Pivot Barriers
    // Task 10: Domain Expertise Barriers
    // Task 11: Business Model Barriers
    // Task 12: Resource/Time Barriers
    // Final aggregation in output expression
  ]
}
```

---

## Task Definitions

### Task 1: Conceptual Territory Uniqueness

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating startup positioning and conceptual differentiation. Assess which ideas occupy unique conceptual territory vs. overlapping/crowded space. Consider: novel problem framing, unexplored domain intersections, paradigm challenges vs. orthodoxy acceptance, and which ideas would be seen as substitutes.

**User Message**: Present all ideas with indices, ask model to vote for which idea has the MOST unique conceptual territory relative to the others.

**Responses**: One response per idea (dynamically generated based on input array length), e.g., "Idea 1 has the most unique conceptual territory", "Idea 2 has the most unique conceptual territory", etc.

**Output Expression**: Extract the probability scores for each idea from `output['scores']`.

---

### Task 2: Network Effect Potential

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating network effects in business models. Assess direct network effects (each user increases value for others), indirect network effects (users attract complementors), and data network effects (more users = better product). Compare relative network effect potential across all ideas.

**User Message**: Present all ideas, ask model to vote for which idea has the STRONGEST network effect potential.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 3: Data Moat Strength

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating data moats and proprietary data advantages. Assess whether each idea would generate data that is hard to replicate, compounding, and defensible. Compare data moat potential across all ideas.

**User Message**: Present all ideas, ask model to vote for which idea has the STRONGEST data moat potential.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 4: Switching Cost Potential

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating switching costs and lock-in. Assess integration depth, data portability friction, learning curve investment, and social graph lock-in. Compare switching cost potential across all ideas.

**User Message**: Present all ideas, ask model to vote for which has the HIGHEST switching cost potential.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 5: Scale Economy Advantages

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating economies of scale. Assess supply-side economies (unit costs decrease with volume), demand-side economies (value increases with customer base), and infrastructure economies (fixed cost advantages). Compare scale advantage potential across all ideas.

**User Message**: Present all ideas, ask model to vote for which has the STRONGEST scale economy advantages.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 6: Dominance Relationships

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating competitive dominance. Identify if any idea is clearly superior to others—solving the same problem more effectively, addressing a superset of use cases, or likely to absorb another's market share. Dominated ideas should receive lower probability; dominating ideas higher.

**User Message**: Present all ideas, ask model to vote for which idea DOMINATES the competitive set (is most likely to outcompete the others if they were in the same market).

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 7: Category Position (Blue/Red Ocean)

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating market positioning strategy. Assess whether each idea is creating a new category (blue ocean) or competing in an existing crowded space (red ocean). Category creators with clear differentiation from all others in the set receive higher scores.

**User Message**: Present all ideas, ask model to vote for which idea has the BEST category positioning (most blue ocean, least red ocean competition).

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 8: Positional Clarity

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating brand and product positioning clarity. Assess clear target customer definition, unambiguous value proposition, consistent positioning, and avoidance of "everything to everyone" syndrome. Compare positional clarity across all ideas.

**User Message**: Present all ideas, ask model to vote for which has the CLEAREST and SHARPEST positioning.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 9: Technical Pivot Barriers

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating technical moats. Assess whether each idea requires deep technical capabilities that take years to develop, or if the technology is shallow and easily copied. Evaluate how hard it would be for OTHER ideas in the set to pivot and replicate each idea's technical approach.

**User Message**: Present all ideas, ask model to vote for which idea has the STRONGEST technical barriers protecting it from the others pivoting into its space.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 10: Domain Expertise Barriers

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating domain expertise requirements. Assess regulatory expertise, industry relationships, and specialized knowledge requirements. Evaluate which ideas require domain expertise that the OTHER ideas in the set would struggle to acquire.

**User Message**: Present all ideas, ask model to vote for which idea has the HIGHEST domain expertise barriers protecting it from competitive pivots.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 11: Business Model Barriers

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating business model conflicts and structural barriers. Assess whether pivoting toward each idea would create conflicting incentives, channel conflicts, or cultural misalignment for the other ideas.

**User Message**: Present all ideas, ask model to vote for which idea has business model structures that MOST PROTECT it from the others pivoting into its space.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

### Task 12: Resource/Time Barriers

**Type**: `vector.completion`

**System Prompt**: Expert at evaluating capital, time, and talent requirements. Assess which ideas require significant resources that others may lack, have first-mover advantages, or require scarce specialized talent.

**User Message**: Present all ideas, ask model to vote for which idea has the HIGHEST resource and time barriers protecting it from competitive replication.

**Responses**: One response per idea.

**Output Expression**: Extract probability scores per idea.

---

## Expressions to Write

### Dynamic Response Generation

For each task, responses must be dynamically generated based on the number of ideas:

```starlark
# In each task's responses field, we need to generate one response per idea
# This will be handled by the output expression aggregating scores
```

### User Message Expression (for each task)

```starlark
# Format all ideas with indices for clear reference
'\n\n'.join(['IDEA ' + str(i+1) + ':\n' + str(idea) for i, idea in enumerate(input['ideas'])])
```

### Task Output Expressions

Each task extracts the probability distribution:
```starlark
output['scores']  # Returns array of probabilities, one per idea
```

### Final Aggregation Expression

The function output aggregates all 12 dimension scores with equal weighting:

```starlark
# Assuming tasks[0] through tasks[11] contain the 12 dimension scores
# Each task output is an array of probabilities for each idea

# Calculate weighted average across all dimensions
def aggregate_scores(task_outputs):
    n_ideas = len(task_outputs[0])
    n_tasks = len(task_outputs)
    
    # Sum scores across all tasks for each idea
    aggregated = [sum(task_outputs[t][i] for t in range(n_tasks)) / n_tasks 
                  for i in range(n_ideas)]
    
    # Normalize to sum to 1
    total = sum(aggregated)
    return [s / total for s in aggregated]

# Actual expression using accumulated task results
[sum([tasks[t][i] for t in range(12)]) / 12 for i in range(len(input['ideas']))]
```

More concretely, the final output expression:
```starlark
# Average across all 12 task outputs, then normalize
raw = [sum([tasks[t][i] for t in range(12)]) for i in range(len(input['ideas']))]
total = sum(raw)
[r / total for r in raw]
```

---

## Test Inputs

### Test 1: Clear Differentiation (3 Ideas, Different Domains)

```json
{
  "ideas": [
    "A B2B SaaS platform that uses AI to automate legal contract review for enterprise law firms, with deep integration into existing legal practice management systems.",
    "A consumer mobile app that gamifies personal fitness with social challenges and rewards, targeting Gen Z users.",
    "A hardware device that monitors industrial equipment vibrations to predict maintenance needs before failures occur, sold to manufacturing plants."
  ]
}
```
**Expected**: Relatively even distribution with slight variation based on moat potential. All three occupy distinct conceptual territory.

---

### Test 2: Overlapping Ideas (4 Ideas, Same Space)

```json
{
  "ideas": [
    "An AI-powered writing assistant that helps marketers create better blog content.",
    "A content generation platform using GPT to write marketing copy for small businesses.",
    "An AI tool that optimizes existing marketing content for SEO and engagement.",
    "A machine learning system that generates personalized email marketing campaigns."
  ]
}
```
**Expected**: Relatively flat distribution—all ideas occupy similar conceptual territory (AI + marketing content). Should show limited differentiation.

---

### Test 3: Dominant Idea Present (3 Ideas, One Clearly Superior)

```json
{
  "ideas": [
    "A food delivery app for a single small town with 10,000 residents.",
    "A nationwide food delivery platform with proprietary logistics optimization, restaurant partnerships in 500 cities, and a loyalty program with 10 million users.",
    "A food delivery app focusing on healthy meal options in suburban areas."
  ]
}
```
**Expected**: Idea 2 should receive significantly higher score—it dominates the others in scale, network effects, and defensibility.

---

### Test 4: Two Ideas (Minimum Set Size)

```json
{
  "ideas": [
    "A peer-to-peer car sharing platform for urban neighborhoods.",
    "An enterprise fleet management SaaS for logistics companies."
  ]
}
```
**Expected**: Both score around 0.5 each—different markets, different moats, no direct competition.

---

### Test 5: Homogeneous Set (5 Nearly Identical Ideas)

```json
{
  "ideas": [
    "A meditation app with guided sessions.",
    "A mindfulness app with breathing exercises.",
    "A wellness app with daily meditation prompts.",
    "A calm app with sleep and meditation audio.",
    "A relaxation app with guided mindfulness sessions."
  ]
}
```
**Expected**: Very flat distribution (each ~0.2). No meaningful differentiation—all are substitute products.

---

### Test 6: Mixed Moat Strengths (4 Ideas)

```json
{
  "ideas": [
    "A social network for professional photographers where portfolios gain visibility based on peer endorsements and client reviews—strong network effects.",
    "A one-time-purchase camera calibration tool with no recurring revenue or user interaction—no moat.",
    "A photography editing software with proprietary AI trained on millions of professional edits, improving with each user—data moat.",
    "An exclusive marketplace connecting top photographers with luxury brand clients, taking years to build relationships—relationship moat."
  ]
}
```
**Expected**: Ideas 1, 3, and 4 score higher due to moats; Idea 2 scores lowest due to lack of defensibility.

---

### Test 7: Category Creation vs. Competition (3 Ideas)

```json
{
  "ideas": [
    "Yet another CRM for small businesses, competing with Salesforce, HubSpot, and hundreds of others.",
    "A 'reverse CRM' where customers manage their relationships with businesses, flipping the paradigm entirely—new category.",
    "A CRM specifically for real estate agents with MLS integration—niche competition."
  ]
}
```
**Expected**: Idea 2 scores highest (category creation, paradigm challenge). Idea 3 moderate (niche positioning). Idea 1 lowest (red ocean, no differentiation).

---

### Test 8: Multimodal Input (Mixed Media Types)

```json
{
  "ideas": [
    "A telehealth platform connecting patients with specialists, featuring secure video consultations and integrated prescription management.",
    ["This is a pitch deck image showing our drone delivery startup", "<image of pitch deck>"],
    "An AI-powered tutoring system that adapts to each student's learning style in real-time."
  ]
}
```
**Expected**: Function should evaluate all three regardless of modality, scoring based on differentiation not presentation quality.

---

### Test 9: Technical Moat Variation (4 Ideas)

```json
{
  "ideas": [
    "A quantum computing platform for drug discovery simulations—requires deep physics expertise and specialized hardware.",
    "A Shopify plugin that adds a wishlist feature—trivially copyable.",
    "A satellite imagery analysis platform using proprietary computer vision models trained on 10 years of data—significant technical barrier.",
    "A mobile app template marketplace—low technical barrier."
  ]
}
```
**Expected**: Ideas 1 and 3 score highest (strong technical moats). Ideas 2 and 4 score lowest (easily replicated).

---

### Test 10: Large Set (8 Ideas, Mixed Domains)

```json
{
  "ideas": [
    "Enterprise cybersecurity platform with AI threat detection.",
    "Consumer fintech app for micro-investing.",
    "B2B logistics optimization SaaS.",
    "Healthcare scheduling platform for clinics.",
    "EdTech platform for corporate training.",
    "PropTech marketplace for commercial real estate.",
    "AgriTech IoT sensors for precision farming.",
    "LegalTech contract automation for startups."
  ]
}
```
**Expected**: Relatively even distribution across diverse, non-overlapping domains. Each should score ~0.125 with small variations based on individual moat strengths.

---

## Implementation Notes

1. **Dynamic Response Count**: Each vector.completion task must dynamically generate responses based on `len(input['ideas'])`. The responses array should contain one option per idea.

2. **Presenting All Ideas**: Each task's user message must present ALL ideas together for comparative evaluation, not evaluate them one at a time.

3. **Normalization**: The final output expression must ensure scores sum to approximately 1.0 (probability distribution).

4. **Equal Weighting**: The 12 dimensions are weighted equally in the initial implementation. Future iterations could adjust weights based on empirical validation.

5. **Edge Case Handling**: 
   - Minimum 2 ideas required (enforced by schema)
   - Homogeneous sets should produce flat distributions
   - Dominant ideas should produce skewed distributions

6. **Starlark Expressions**: All dynamic content (user messages, response generation, output aggregation) uses Starlark expressions to handle variable-length input arrays.
